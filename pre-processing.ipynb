{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c178212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from s2sphere import CellId, LatLng\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e105ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_parquet('gojek/demand/201910.parquet')\n",
    "df2 = pd.read_parquet('gojek/driver_log/201910.parquet')              \n",
    "mymap_path = 'map/region_map.pdf'\n",
    "region_names_path = 'map/Regions_With_Names.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ba1a013",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df1=df1[['booking_time','booking_pickup_latitude','booking_pickup_longitude','booking_destination_latitude','booking_destination_longitude','status']]\n",
    "new_df2 = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95dda43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group into 15 min intervals\n",
    "grouped1 = new_df1.groupby(pd.Grouper(key='booking_time', freq='15Min'))\n",
    "for key, group in grouped1:\n",
    "    #print(f\"Group {key}:\")\n",
    "    #print(group)\n",
    "    break\n",
    "    \n",
    "    \n",
    "grouped2 = new_df2.groupby(pd.Grouper(key='timestamp', freq='15Min'))\n",
    "for key, group in grouped2:\n",
    "    #print(f\"Group {key}:\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eff3c90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_point_inside_area(point, area_coordinates):\n",
    "    # check if given point coordinates are within a certain area\n",
    "    lon, lat = point\n",
    "    top_left = area_coordinates[0]\n",
    "    bottom_right = area_coordinates[2]\n",
    "\n",
    "    if (\n",
    "        lon >= top_left[0] and\n",
    "        lon <= bottom_right[0] and\n",
    "        lat >= top_left[1] and\n",
    "        lat <= bottom_right[1]\n",
    "    ):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def getTT(region):\n",
    "    return round((((region-100)//50) * -5.2222 ) + 147.11),round((((region%50)-2) * 5.2083)+20.458 )\n",
    "\n",
    "def coordinate2region(coordinates, data):\n",
    "    for d in data:\n",
    "        for area in d['geometry']['coordinates'][0]:\n",
    "            if is_point_inside_area([coordinates[1], coordinates[0]], area):\n",
    "                return d['properties']['id']\n",
    "            \n",
    "def sid2coordinates(sid):\n",
    "    cell = CellId(sid)\n",
    "    center = cell.to_lat_lng()\n",
    "    latitude = center.lat().degrees\n",
    "    longitude = center.lng().degrees\n",
    "    return (latitude, longitude)\n",
    "\n",
    "def sid2coordinates_new(sid):\n",
    "    sid = int(sid)\n",
    "    cell = CellId(sid)\n",
    "    center = cell.to_lat_lng()\n",
    "    latitude = center.lat().degrees\n",
    "    longitude = center.lng().degrees\n",
    "    return (latitude, longitude)\n",
    "\n",
    "def normalize_array(myarray,new_min,new_max):\n",
    "    # Calculate the scaling factor\n",
    "    min_value = myarray.min()\n",
    "    max_value = myarray.max()\n",
    "    scaling_factor = (new_max - new_min) / (max_value - min_value)\n",
    "\n",
    "    # Normalize the data to the new range\n",
    "    normalized_array = (myarray - min_value) * scaling_factor + new_min\n",
    "    return normalized_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9ef705",
   "metadata": {},
   "source": [
    "## IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0edb6d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap dimensions\n",
    "mydf = new_df1\n",
    "width, height = 267, 163\n",
    "region_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079b5ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create/populate/save heatmap\n",
    "mymap_path = 'map/region_map.pdf'\n",
    "region_names_path = 'map/Regions_With_Names.json'\n",
    "\n",
    "with open(region_names_path, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "    # create and populate heatmap for every 15 mins\n",
    "    name = 0\n",
    "    for key, group in grouped1:\n",
    "        # Create empty arrays for each channel\n",
    "        red_channel = np.full((height, width),0, dtype=np.uint8)\n",
    "        green_channel = np.full((height, width),0, dtype=np.uint8)\n",
    "        blue_channel = np.full((height, width),0, dtype=np.uint8)\n",
    "        \n",
    "        for index in range(len(group)):\n",
    "            \n",
    "            row = group.iloc[index]\n",
    "\n",
    "            # populate red\n",
    "            coordinates = (row['booking_pickup_latitude'], row['booking_pickup_longitude'])\n",
    "            rid = coordinate2region(coordinates, data)\n",
    "            if rid is not None:\n",
    "                t,tt = getTT(int(rid))\n",
    "\n",
    "                top_left_x = t - region_size // 2\n",
    "                top_left_y = tt - region_size // 2\n",
    "\n",
    "                for y in range(top_left_y, top_left_y + region_size):\n",
    "                    for x in range(top_left_x, top_left_x + region_size):\n",
    "                        red_channel[x, y] += 1\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            # populate green\n",
    "            coordinates = (row['booking_destination_latitude'], row['booking_destination_longitude'])\n",
    "            rid = coordinate2region(coordinates, data)\n",
    "            if rid is not None:\n",
    "                t,tt = getTT(int(rid))\n",
    "\n",
    "                top_left_x = t - region_size // 2\n",
    "                top_left_y = tt - region_size // 2\n",
    "\n",
    "                for y in range(top_left_y, top_left_y + region_size):\n",
    "                    for x in range(top_left_x, top_left_x + region_size):\n",
    "                        green_channel[x, y] += 1\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        blue_group = grouped2.get_group(key)\n",
    "        blue_group = blue_group[blue_group['driver_status'] == 1]\n",
    "        \n",
    "        for index in range(len(blue_group)):\n",
    "            row = blue_group.iloc[index]\n",
    "            \n",
    "            # populate blue\n",
    "            coordinates = sid2coordinates(int(row['s2id']))\n",
    "            rid = coordinate2region(coordinates, data)\n",
    "            if rid is not None:\n",
    "                t,tt = getTT(int(rid))\n",
    "\n",
    "                top_left_x = t - region_size // 2\n",
    "                top_left_y = tt - region_size // 2\n",
    "\n",
    "                for y in range(top_left_y, top_left_y + region_size):\n",
    "                    for x in range(top_left_x, top_left_x + region_size):\n",
    "                        blue_channel[x, y] += 1\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        # combine channels and save heatmap\n",
    "        # Create a blank RGB image\n",
    "        heatmap = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "        # Assign the red, green, and blue channels\n",
    "        red_channel = normalize_array(red_channel,8,255)\n",
    "        green_channel = normalize_array(green_channel,48,255)\n",
    "        blue_channel = normalize_array(blue_channel,107,255)\n",
    "        heatmap[:, :, 0] = red_channel\n",
    "        heatmap[:, :, 1] = green_channel\n",
    "        heatmap[:, :, 2] = blue_channel\n",
    "\n",
    "        # Convert the NumPy array to a PIL Image\n",
    "        heatmap_image = Image.fromarray(heatmap)\n",
    "        name+=1\n",
    "        heatmap_image.save(f\"myfiles/images/{str(name)}.png\")\n",
    "        \n",
    "        if name % 20 == 0:\n",
    "            print(name/2920)\n",
    "        #break # remove this break. for testing only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dcecfa",
   "metadata": {},
   "source": [
    "## CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa91fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_regions = [429,430] # select your regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8caf2c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymap_path = 'map/region_map.pdf'\n",
    "region_names_path = 'map/Regions_With_Names.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d492fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def related_regions(rid):\n",
    "    # returns a list of regions surrounding the input region. Excludes input region\n",
    "    related_list = str(set([rid-1,rid+1,rid-50,rid+50,rid-49,rid+49,rid-51,rid+51]))\n",
    "    related = []\n",
    "    with open(f'{folder}/Regions_With_Names.json', 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        for d in data:\n",
    "            currentid = d['properties']['id']\n",
    "            if currentid in related_list:\n",
    "                related.append(currentid)\n",
    "    return related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2dd0200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 2019-10-01 00:00:00:\n",
      "       driver_id           timestamp          s2id  driver_status\n",
      "11     700653815 2019-10-01 00:00:00  3.592208e+18              1\n",
      "16     700429849 2019-10-01 00:00:00  3.592202e+18              1\n",
      "19     700276871 2019-10-01 00:00:00  3.592251e+18              1\n",
      "25     700136282 2019-10-01 00:00:00  3.592208e+18              1\n",
      "29     700261045 2019-10-01 00:00:00  3.592203e+18              1\n",
      "...          ...                 ...           ...            ...\n",
      "38585  700121418 2019-10-01 00:14:00  3.592251e+18              1\n",
      "38586  700285980 2019-10-01 00:14:00  3.592206e+18              1\n",
      "38590  700383682 2019-10-01 00:14:00  3.592213e+18              1\n",
      "38594  700316017 2019-10-01 00:14:00  3.592202e+18              1\n",
      "38595  700358707 2019-10-01 00:14:00  3.592212e+18              1\n",
      "\n",
      "[9931 rows x 4 columns]\n",
      "2976\n"
     ]
    }
   ],
   "source": [
    "new_df2 = new_df2[new_df2['driver_status'] == 1]\n",
    "grouped2 = new_df2.groupby(pd.Grouper(key='timestamp', freq='15Min'))\n",
    "for key, group in grouped2:\n",
    "    print(f\"Group {key}:\")\n",
    "    print(group)\n",
    "    break\n",
    "print(len(grouped2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d360e5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'select_regions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v5/jq15pcw16xxd70l_q9672pvr0000gn/T/ipykernel_66092/3147941041.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregion_names_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mregion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselect_regions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{region} start'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'select_regions' is not defined"
     ]
    }
   ],
   "source": [
    "mymap_path = 'map/region_map.pdf'\n",
    "region_names_path = 'map/Regions_With_Names.json'\n",
    "\n",
    "with open(region_names_path, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    for region in select_regions:\n",
    "        print(f'{region} start')\n",
    "        count = 0\n",
    "\n",
    "        related = related_regions(region)\n",
    "        col_names = [str(region),str(region)+\"_end\",\"weekday\",\"dayofweek\",\"hour\",\"minute\",\"day\",\"holiday\"\n",
    "            ,\"freetaxi\",related[0],related[1],related[2],related[3],related[4],related[5],related[6],related[7]\n",
    "            ,related[0]+\"_end\",related[1]+\"_end\",related[2]+\"_end\",related[3]+\"_end\"\n",
    "             ,related[4]+\"_end\",related[5]+\"_end\",related[6]+\"_end\",related[7]+\"_end\"]\n",
    "        processed_df = pd.DataFrame(None, columns=col_names)\n",
    "        \n",
    "        for key, group in grouped1:\n",
    "            temp_list = [0] * len(processed_df.columns) # input all data into this list, then append to processed_df\n",
    "            for index, row in group.iterrows():\n",
    "                pickup_coordinates = (row['booking_pickup_latitude'], row['booking_pickup_longitude'])\n",
    "                pickup_rid = coordinate2region(pickup_coordinates, data)\n",
    "                if pickup_rid is not None:\n",
    "                    if int(pickup_rid) == region:\n",
    "                        temp_list[0] += 1\n",
    "                    elif pickup_rid in related:\n",
    "                        temp_index = related.index(pickup_rid)\n",
    "                        temp_list[temp_index+9] += 1\n",
    "\n",
    "                end_coordinates = (row['booking_destination_latitude'], row['booking_destination_longitude'])\n",
    "                end_rid = coordinate2region(end_coordinates, data)\n",
    "                if end_rid is not None:\n",
    "                    if int(end_rid) == region:\n",
    "                        temp_list[1] += 1\n",
    "                    elif end_rid in related:\n",
    "                        temp_index = related.index(end_rid)\n",
    "                        temp_list[temp_index+9+8] += 1\n",
    "\n",
    "            blue_group = grouped2.get_group(key)\n",
    "            numfreetaxis = 0\n",
    "            freetaxi_coordinates = blue_group['s2id'].apply(sid2coordinates_new)\n",
    "            for lat, lon in freetaxi_coordinates:\n",
    "                freetaxi_rid = coordinate2region((lat,lon), data)\n",
    "                if freetaxi_rid is not None:\n",
    "                    if int(freetaxi_rid) == region:\n",
    "                        numfreetaxis+=1\n",
    "            temp_list[8] = numfreetaxis\n",
    "\n",
    "            if key.dayofweek in [5,6]:\n",
    "                temp_list[2] = 0\n",
    "            elif key.dayofweek in [0,1,2,3,4]:\n",
    "                temp_list[2] = 1\n",
    "            temp_list[3] = key.dayofweek\n",
    "            temp_list[4] = key.hour\n",
    "            temp_list[5] = key.minute\n",
    "            temp_list[6] = key.day\n",
    "            # holiday\n",
    "            if key.day in [27,28]: # insert holiday dates for the month here\n",
    "                temp_list[7] = 1\n",
    "            else:\n",
    "                temp_list[7] = 0\n",
    "            processed_df.loc[key] = temp_list\n",
    "            count += 1\n",
    "            if count % 50 == 0:\n",
    "                print(count/2976)\n",
    "        print(f'{region} done')\n",
    "        processed_df.to_csv(f'myfiles/csv/{region}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590e589e",
   "metadata": {},
   "source": [
    "## Micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "776ff590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610 start\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/420ass1/lib/python3.7/site-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m_get_deprecated_option\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deprecated_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mode.data_manager'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v5/jq15pcw16xxd70l_q9672pvr0000gn/T/ipykernel_66316/1806303913.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m's2id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coords'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m's2id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msid2coordinates_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoordinate2region\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coords'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrid\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/420ass1/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36miterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1264\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/420ass1/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    439\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                 \u001b[0mmanager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.data_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmanager\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"block\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/420ass1/lib/python3.7/site-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__func__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/420ass1/lib/python3.7/site-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m_get_option\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_single_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m# walk the nested dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/420ass1/lib/python3.7/site-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m_get_single_key\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0m_warn_if_deprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_translate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/420ass1/lib/python3.7/site-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m_warn_if_deprecated\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0mbool\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \"\"\"\n\u001b[0;32m--> 626\u001b[0;31m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_deprecated_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/420ass1/lib/python3.7/site-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m_get_deprecated_option\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m    586\u001b[0m     \"\"\"\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deprecated_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# RUN THIS CELL ONLY IF '{region}_locations.json' has not yet been created\n",
    "\n",
    "\n",
    "mymap_path = f'map/region_map.pdf'\n",
    "region_names_path = f'map/Regions_With_Names.json'\n",
    "#select_regions = ['428', '610', '929']\n",
    "select_regions = ['610']\n",
    "\n",
    "def sid2coordinates(sid):\n",
    "    sid = int(sid)  # Convert to integer\n",
    "    cell = CellId(sid)\n",
    "    center = cell.to_lat_lng()\n",
    "    latitude = center.lat().degrees\n",
    "    longitude = center.lng().degrees\n",
    "    return (latitude, longitude)\n",
    "\n",
    "with open(region_names_path, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "for region in select_regions:\n",
    "    print(f'{region} start')\n",
    "    count = 0\n",
    "    myset = set()\n",
    "\n",
    "    for _, group in grouped2:\n",
    "        group = group.dropna(subset=['s2id'])\n",
    "        group['coords'] = group['s2id'].apply(sid2coordinates_new)\n",
    "        for _, row in group.iterrows():\n",
    "            rid = coordinate2region(row['coords'], data)\n",
    "            if rid != None:\n",
    "                if rid == region:\n",
    "                    myset.add(row['s2id'])\n",
    "        \n",
    "        count += 1\n",
    "        if count % 50 == 0:\n",
    "            print(len(myset))\n",
    "            print(count / len(grouped2))\n",
    "\n",
    "            # Convert set to a list\n",
    "            mylist = list(myset)\n",
    "\n",
    "            # Specify the file path\n",
    "            output_file_path = f\"locations/{region}_locations.json\"\n",
    "\n",
    "            # Write the list to the file in JSON format\n",
    "            with open(output_file_path, 'w') as file:\n",
    "                json.dump(mylist, file)\n",
    "\n",
    "            print(f\"Set contents saved to {output_file_path}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9908da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymap_path = f'map/region_map.pdf'\n",
    "region_names_path = f'map/Regions_With_Names.json'\n",
    "select_regions = ['428', '610', '929']\n",
    "with open(\"locations/428_locations.json\", 'r') as json_file:\n",
    "    data_428 = json.load(json_file) \n",
    "with open(\"locations/610_locations.json\", 'r') as json_file:\n",
    "    data_610 = json.load(json_file) \n",
    "with open(\"locations/929_locations.json\", 'r') as json_file:\n",
    "    data_929 = json.load(json_file) \n",
    "\n",
    "mylocations = {select_regions[0]: data_428, select_regions[1]: data_610, select_regions[2]: data_929}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051c9898",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(region_names_path, 'r') as json_file:\n",
    "    data = json.load(json_file) \n",
    "    \n",
    "for region in select_regions:\n",
    "    print(f'{region} start')\n",
    "    count = 0\n",
    "    \n",
    "    col_names = mylocations[region]\n",
    "    processed_df = pd.DataFrame(None, columns=col_names)\n",
    "    temp_list = [-15] * len(processed_df.columns) # add data to temp_list then append to processed df\n",
    "    \n",
    "    for key, group in grouped2:\n",
    "        temp_list = [x + 15 for x in temp_list]\n",
    "        group = group.dropna(subset=['s2id'])\n",
    "        group['coords'] = group['s2id'].apply(sid2coordinates_new)\n",
    "        for _, row in group.iterrows():\n",
    "            rid = coordinate2region(row['coords'], data)\n",
    "            if rid != None:\n",
    "                if rid == region:\n",
    "                    if row['s2id'] in mylocations[region]:\n",
    "                        myindex = mylocations[region].index(row['s2id']) # get index to append to temp_list\n",
    "                        if row['driver_status'] == 1: # vacant\n",
    "                            temp_list[myindex] = 0 # time elapsed since last \n",
    "        processed_df.loc[key] = temp_list\n",
    "        count += 1\n",
    "        if count % 50 == 0:\n",
    "            print(count / len(grouped2))\n",
    "            \n",
    "    processed_df.to_csv(f'micro/{region}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
